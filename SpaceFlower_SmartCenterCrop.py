import hashlib
import os
import json
import comfy
# import random
import random
import sys
# from tkinter import messagebox
import cv2
import torch
import numpy as np
import nodes
import folder_paths
from PIL import Image, ImageGrab
from .terminalcolors import tcolor, color_text
from server import PromptServer
from aiohttp import web
# import cv2
import tkinter as tk
from PIL import Image, ImageTk, ImageDraw, ImageOps
from PIL.PngImagePlugin import PngInfo
from comfy.cli_args import args
# import subprocess
# from torchvision import transforms
from nodes import SaveImage
import time
from tkinter import filedialog
from .SpaceFlower_SaveImage import SpaceFlower_SaveImage
from comfy.model_management import InterruptProcessingException
import torchvision.transforms as transforms
from nodes import MAX_RESOLUTION
import torch.nn.functional as F
import shutil
try:
    import torchvision.transforms.v2 as T
except ImportError:
    import torchvision.transforms as T
    
from comfy.utils import ProgressBar, common_upscale

#32 ìŠ¤ë§ˆíŠ¸ ê°ì²´ ì˜ì—­ ìë¥´ê¸°ê¸°
class SpaceFlower_SmartCenterCrop:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "width": ("INT", {"default": 1024, "min": 64, "max": 8192, "step": 8}),
                "height": ("INT", {"default": 1536, "min": 64, "max": 8192, "step": 8}),
                # ê°ì§€í•  ë°°ê²½ìƒ‰ (ì´ ìƒ‰ì´ ì•„ë‹Œ ë¶€ë¶„ì„ ìºë¦­í„°ë¡œ ì¸ì‹)
                "detect_bg_color": (["white", "black", "gray"], {"default": "white"}),
                # ì—¬ë°±ì´ ìƒê¸¸ ê²½ìš° ì±„ìš¸ ìƒ‰ìƒ
                "pad_color": (["white", "black", "gray"], {"default": "white"}),
                # ìºë¦­í„° ì¸ì‹ ë¯¼ê°ë„ (0.01 ~ 1.0, ë‚®ì„ìˆ˜ë¡ ë¯¸ì„¸í•œ ìƒ‰ì°¨ì´ë„ ìºë¦­í„°ë¡œ ì¸ì‹)
                "tolerance": ("FLOAT", {"default": 0.05, "min": 0.0, "max": 1.0, "step": 0.01}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("cropped_image",)
    FUNCTION = "smart_crop"
    CATEGORY = "ğŸŒ»SpaceFlower/Image"

    def smart_crop(self, image, width, height, detect_bg_color, pad_color, tolerance):
        # ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
        out_images = []

        # ë°°ì¹˜ ë‚´ì˜ ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ë°˜ë³µ ì²˜ë¦¬
        for img in image:
            # 1. í…ì„œë¥¼ numpyë¡œ ë³€í™˜ (H, W, C)
            np_img = img.cpu().numpy()
            h, w, c = np_img.shape

            # 2. ë°°ê²½ìƒ‰ ê¸°ì¤€ê°’ ì„¤ì • (RGB)
            if detect_bg_color == "white":
                target_bg = np.array([1.0, 1.0, 1.0])
            elif detect_bg_color == "black":
                target_bg = np.array([0.0, 0.0, 0.0])
            else: # gray
                target_bg = np.array([0.5, 0.5, 0.5])

            # 3. ìºë¦­í„° ì˜ì—­ ê°ì§€ (ë°°ê²½ìƒ‰ê³¼ ì°¨ì´ê°€ toleranceë³´ë‹¤ í° í”½ì…€ ì°¾ê¸°)
            # í”½ì…€ë³„ë¡œ ë°°ê²½ìƒ‰ê³¼ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°
            diff = np.abs(np_img - target_bg)
            # RGB ì±„ë„ ì¤‘ í•˜ë‚˜ë¼ë„ ì°¨ì´ê°€ í¬ë©´ ê°ì²´ë¡œ ê°„ì£¼
            mask = np.any(diff > tolerance, axis=-1)

            # ê°ì²´ í”½ì…€ì˜ ì¢Œí‘œ ì°¾ê¸°
            coords = np.argwhere(mask)

            if len(coords) > 0:
                # Bounding Box ê³„ì‚° (y_min, x_min, y_max, x_max)
                y_min, x_min = coords.min(axis=0)
                y_max, x_max = coords.max(axis=0)
                
                # ìºë¦­í„°ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
                center_y = (y_min + y_max) // 2
                center_x = (x_min + x_max) // 2
            else:
                # ìºë¦­í„°ê°€ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ì´ë¯¸ì§€ ì •ì¤‘ì•™ì„ ê¸°ì¤€ìœ¼ë¡œ í•¨
                center_y = h // 2
                center_x = w // 2

            # 4. í¬ë¡­í•  ì˜ì—­ ê³„ì‚° (Target Box)
            # ì¤‘ì‹¬ì ì„ ê¸°ì¤€ìœ¼ë¡œ width, height í¬ê¸°ì˜ ë°•ìŠ¤ ì¢Œí‘œ ê³„ì‚°
            crop_y_min = center_y - (height // 2)
            crop_x_min = center_x - (width // 2)
            crop_y_max = crop_y_min + height
            crop_x_max = crop_x_min + width

            # 5. ê²°ê³¼ ìº”ë²„ìŠ¤ ìƒì„± (ì§€ì •ëœ pad_colorë¡œ ì±„ì›€)
            pad_val = 0.0
            if pad_color == "white": pad_val = 1.0
            elif pad_color == "gray": pad_val = 0.5
            
            # (H, W, C) í¬ê¸°ì˜ ìº”ë²„ìŠ¤ ìƒì„±
            canvas = np.full((height, width, c), pad_val, dtype=np.float32)

            # 6. ì›ë³¸ ì´ë¯¸ì§€ì™€ í¬ë¡­ ì˜ì—­ì˜ êµì°¨ êµ¬ê°„(Intersection) ê³„ì‚°
            # ì›ë³¸ ì´ë¯¸ì§€ ë‚´ì—ì„œ ìœ íš¨í•œ ì¢Œí‘œ ë²”ìœ„
            src_x1 = max(0, crop_x_min)
            src_y1 = max(0, crop_y_min)
            src_x2 = min(w, crop_x_max)
            src_y2 = min(h, crop_y_max)

            # ìº”ë²„ìŠ¤ ë‚´ì—ì„œ ë³µì‚¬ë  ìœ„ì¹˜ ì¢Œí‘œ ë²”ìœ„
            dst_x1 = max(0, -crop_x_min)
            dst_y1 = max(0, -crop_y_min)
            # ë³µì‚¬í•  ë„ˆë¹„ì™€ ë†’ì´
            copy_w = src_x2 - src_x1
            copy_h = src_y2 - src_y1

            # ìœ íš¨í•œ ì˜ì—­ì´ ìˆì„ ê²½ìš°ì—ë§Œ ë³µì‚¬
            if copy_w > 0 and copy_h > 0:
                canvas[dst_y1:dst_y1+copy_h, dst_x1:dst_x1+copy_w, :] = \
                    np_img[src_y1:src_y1+copy_h, src_x1:src_x1+copy_w, :]

            # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ (Tensorë¡œ ë³€í™˜)
            out_images.append(torch.from_numpy(canvas))

        # ë¦¬ìŠ¤íŠ¸ë¥¼ ìŠ¤íƒí•˜ì—¬ ë°°ì¹˜ í…ì„œë¡œ ë°˜í™˜ (B, H, W, C)
        return (torch.stack(out_images),)